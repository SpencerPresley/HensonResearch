{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn # For building NN layers\n",
    "import torch.optim as optim # For optimization algorithms (Adam, SGD, etc)\n",
    "import torchvision.transforms as transforms # For preprocessing images\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN (nn.Module):\n",
    "    def __init__ (self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn_layer_1 = nn.Conv2d(1, 32, kernel_size=3, \n",
    "                                     stride=1, padding=1)\n",
    "        self.cnn_layer_2 = nn.Conv2d(32, 64, kernel_size=3, \n",
    "                                     stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128) # 64 filters, image size = 7x7 after pooling\n",
    "        self.fc2 = nn.Linear(128, 10) # 10 output classes for MNIST digts (0-9)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.cnn_layer_1(x)))\n",
    "        x = self.pool(F.relu(self.cnn_layer_2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7) # Flatten the tensor for fully connected layers\n",
    "        x = F.relu(self.fc1(x)) # Apply ReLU activation to the first FC layer\n",
    "        x = self.fc2(x) # Apply the second FC layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the loss and optimizer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # Loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5))])\n",
    "\n",
    "trainset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train() # set model to training mode\n",
    "for images, labels in trainloader:\n",
    "    optimizer.zero_grad() # Zero the gradients to prevent accumulation of gradients from previous iterations\n",
    "    outputs = model(images) # Forward pass\n",
    "    loss = criterion(outputs, labels) # Calculate the loss\n",
    "    loss.backward() # Backward pass\n",
    "    optimizer.step() # Update model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate  model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the networks on the 10,000 test images: 98 %\n"
     ]
    }
   ],
   "source": [
    "model.eval() # Set model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad(): # Inference mode, gradients aren't needed\n",
    "    for images, labels in testloader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1) # Get the index of the max log probability\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "print('Accuracy of the networks on the 10,000 test images: %d %%' % (100 * correct / total))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
